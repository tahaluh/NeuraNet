{
  "home": {
    "welcomeMessage": "¡Bienvenido a NeuraNet!",
    "about": "Sobre Nosotros",
    "contact": "Contacto"
  },
  "decisionBoundary": {
    "title": "Límite de Decisión",
    "content": {
      "page1": [
        "El \"Límite de Decisión\" es un concepto crucial en las redes neuronales. Representa una línea o límite que separa diferentes grupos de datos en un gráfico.",
        "Por ejemplo, en el gráfico con puntos &blue(azules)& y &red(rojos)&, el \"Límite de Decisión\" es la línea blanca que divide estos puntos en grupos distintos.",
        "Este límite es esencial para que el modelo de red neuronal tome decisiones precisas y clasifique correctamente los puntos de datos en sus respectivas categorías."
      ]
    }
  },
  "weights": {
    "title": "Pesos",
    "content": {
      "page1": [
        "Los pesos de conexión entre una entrada y una salida en una red neuronal son cruciales, ya que controlan la importancia de las conexiones en la propagación de datos y el cálculo de la salida.",
        "Durante el entrenamiento, estos pesos se ajustan para que la red pueda aprender a realizar tareas específicas con mayor precisión y eficacia. Determinan cuán relevante es la información transmitida por un neurón en particular para la clasificación final.",
        "En el gráfico adyacente, por ejemplo, el valor recibido por el neurón \"output1\" determina la probabilidad de que un punto se clasifique como azul, mientras que el valor recibido por \"output2\" determina la probabilidad de que se clasifique como rojo."
      ],
      "page2": [
        "Ajustar los pesos permite definir de manera más clara el límite de decisión. Los valores de cada peso impactan directamente en la posición y forma de este límite, influyendo en la capacidad de la red neuronal para separar diferentes clases de datos de manera más precisa y discriminatoria.",
        "Ajusta los pesos para que los puntos se clasifiquen correctamente."
      ]
    }
  },
  "bias": {
    "title": "Sesgo",
    "content": {
      "page1": [
        "El \"sesgo\" en una red neuronal es un valor adicional en un neurón, además de los pesos de conexión. Permite que el neurón ajuste su punto de partida antes de aplicar la función de activación, controlando el nivel de activación del neurón.",
        "La función principal del \"sesgo\" es permitir que la red neuronal se adapte mejor a los datos de entrenamiento, especialmente en escenarios no lineales. Por ejemplo, cuando los datos no pueden separarse por una línea recta, el límite de decisión necesario también será no lineal. El \"sesgo\" permite este ajuste desplazando verticalmente el límite de decisión, para que la red pueda clasificar correctamente los datos."
      ],
      "page2": [
        "Al agregar el \"sesgo\" a la fórmula de cálculo de la salida, la red neuronal gana flexibilidad y la capacidad de ajustarse a los datos. Esto permite capturar relaciones complejas en los datos y mejorar la precisión de la clasificación. El \"sesgo\" permite crear límites de decisión más precisos y discriminatorios, haciendo que la red sea más adaptable al proceso de aprendizaje.",
        "Ajusta los valores de los pesos y el sesgo para que los puntos se clasifiquen correctamente."
      ]
    }
  },
  "hiddenLayers": {
    "title": "Capas Ocultas",
    "content": {
      "page1": [
        "Las \"capas ocultas\" son componentes centrales de las redes neuronales, operando en un espacio intermedio entre las capas de entrada y salida. Su función es extraer y aprender características complejas de los datos, permitiendo que la red aprenda representaciones jerárquicas de los mismos.",
        "Cuanto más \"capas ocultas\", mayor es la capacidad de la red para aprender y representar características complejas, aunque esto puede presentar desafíos de entrenamiento."
      ],
      "page2": [
        "Las \"capas ocultas\" permiten la clasificación de relaciones no lineales en los datos. Sin embargo, aumentar el número de \"capas ocultas\" puede hacer que el ajuste de pesos sea más desafiante. Encontrar el equilibrio adecuado entre la cantidad de capas y el tamaño de la red es crucial para lograr resultados precisos en tareas de aprendizaje automático complejas.",
        "En el gráfico adyacente, se puede observar un alto número de pesos que deben configurarse. El proceso de ajustar tantos pesos puede ser laborioso y requerir más tiempo de entrenamiento. Por esta razón, es importante considerar cuidadosamente la complejidad del problema al diseñar la arquitectura de la red neuronal.",
        "Además, a pesar del aumento en el número de conexiones y neurones en la red, la relación de clasificación aún sigue siendo lineal. Este problema puede resolverse con \"Funciones de Activación\", que son funciones no lineales aplicadas a los neurones en las \"capas ocultas\"."
      ]
    }
  },
  "activationFunction": {
    "title": "Funciones de Activación",
    "content": {
      "page1": [
        "Las \"Funciones de Activación\" son funciones matemáticas aplicadas a los neurones de las capas ocultas de una red neuronal. Introducen no linealidad en el modelo, permitiendo que la red aprenda y represente relaciones complejas y no lineales en los datos.",
        "Estas funciones son cruciales para desbloquear el poder del aprendizaje no lineal de las redes neuronales, posibilitando la resolución de problemas más complejos y la obtención de clasificaciones más precisas en tareas de aprendizaje automático.",
        "A continuación, se presentan algunas de las funciones de activación más comunes para los neurones en redes neuronales. Cada función tiene características específicas que afectan el rendimiento de la red. La elección de la función de activación es fundamental para el éxito de la red en diversas aplicaciones de aprendizaje automático, como visión por computadora y procesamiento de lenguaje natural."
      ],
      "page2": [
        "Para nuestra demostración, utilizaremos la función sigmoide. Es importante señalar que, al ajustar los pesos, se puede observar la formación de curvas en el límite de decisión, lo que resulta en una clasificación no lineal.",
        "Gracias a la función sigmoide elegida, este proceso se vuelve más suave, permitiendo que la red aprenda y represente relaciones complejas en los datos de manera más efectiva."
      ]
    }
  },"utils": {
    "lang": "es-es",
    "next": "Siguiente",
    "previous": "Anterior"
  }
  
}
