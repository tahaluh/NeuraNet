{
  "home": {
    "welcomeMessage": "Welcome to NeuraNet!",
    "about": "About Us",
    "contact": "Contact"
  },
  "decisionBoundary": {
    "title": "Decision Boundary",
    "content": {
      "page1": [
        "The \"Decision Boundary\" is a crucial concept in neural networks. It represents a line or boundary that separates different groups of data on a graph.",
        "For example, in the graph with &blue(blue)& and &red(red)& points, the \"Decision Boundary\" is the white line that divides these points into distinct groups.",
        "This boundary is essential for the neural network model to make accurate decisions and correctly classify data points into their respective categories."
      ]
    }
  },
  "weights": {
    "title": "Weights",
    "content": {
      "page1": [
        "The connection weights between an input and an output in a neural network are crucial, as they control the importance of connections in data propagation and output calculation.",
        "During training, these weights are adjusted so that the network can learn to perform specific tasks with greater accuracy and effectiveness. They determine how relevant the information passed by a particular neuron is for the final classification.",
        "In the adjacent graph, for instance, the value received by the \"output1\" neuron determines the probability of a point being classified as blue, while the value received by \"output2\" determines the probability of it being red."
      ],
      "page2": [
        "Adjusting the weights allows for a clearer definition of the decision boundary. The values of each weight directly impact the position and shape of this boundary, influencing the neural network's ability to separate different data classes more precisely and discriminatively.",
        "Adjust the weights so that the points are classified correctly."
      ]
    }
  },
  "bias": {
    "title": "Bias",
    "content": {
      "page1": [
        "The \"bias\" in a neural network is an additional value in a neuron, apart from the connection weights. It allows the neuron to adjust its starting point before applying the activation function, controlling the neuron's activation level.",
        "The main function of the \"bias\" is to enable the neural network to better adapt to training data, especially in non-linear scenarios. For example, when data cannot be separated by a straight line, the required decision boundary will also be non-linear. The \"bias\" allows for this adjustment by vertically shifting the decision boundary, so the network can correctly classify the data."
      ],
      "page2": [
        "By adding the \"bias\" to the output calculation formula, the neural network gains flexibility and the ability to adjust to the data. This enables capturing complex relationships in the data and improving classification accuracy. The \"bias\" allows for creating more precise and discriminative decision boundaries, making the network more adaptable to the learning process.",
        "Adjust the values of the weights and bias so that the points are classified correctly."
      ]
    }
  },
  "hiddenLayers": {
    "title": "Hidden Layers",
    "content": {
      "page1": [
        "\"Hidden layers\" are central components of neural networks, operating in an intermediate space between input and output layers. Their function is to extract and learn complex features from the data, enabling the network to learn hierarchical representations of the same.",
        "The more \"hidden layers,\" the greater the network's capacity to learn and represent complex features, although this may pose training challenges."
      ],
      "page2": [
        "\"Hidden layers\" enable the classification of non-linear relationships in the data. However, increasing the number of \"hidden layers\" can make weight adjustment more challenging. Striking the right balance between the number of layers and the network's size is crucial for achieving accurate results in complex machine learning tasks.",
        "In the adjacent graph, a high number of weights to be configured can be observed. The process of adjusting so many weights can be laborious and demand more training time. For this reason, it's important to carefully consider the problem's complexity when designing the neural network architecture.",
        "Furthermore, despite the increased number of connections and neurons in the network, the classification relationship still remains linear. This problem can be addressed with \"Activation Functions,\" which are non-linear functions applied to neurons in the \"hidden layers.\""
      ]
    }
  },
  "activationFunction": {
    "title": "Activation Functions",
    "content": {
      "page1": [
        "\"Activation Functions\" are mathematical functions applied to neurons in the hidden layers of a neural network. They introduce non-linearity to the model, enabling the network to learn and represent complex, non-linear relationships in the data.",
        "These functions are crucial to unlock the power of non-linear learning in neural networks, allowing the resolution of more complex problems and achieving more accurate classifications in machine learning tasks.",
        "Some of the most common activation functions for neurons in neural networks are shown above. Each function has specific characteristics that affect the network's performance. Choosing the appropriate activation function is essential for the network's success in various machine learning applications, such as computer vision and natural language processing."
      ],
      "page2": [
        "For our demonstration, we will use the sigmoid function. It's important to note that, while adjusting the weights, the formation of curves in the decision boundary can be observed, resulting in non-linear classification.",
        "Thanks to the chosen sigmoid function, this process becomes smoother, enabling the network to learn and represent complex relationships in the data more effectively."
      ]
    }
  }
}
